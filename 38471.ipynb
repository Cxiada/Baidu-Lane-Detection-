{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "# !ls /home/aistudio/data/\n",
    "!ls /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压\n",
    "# !unzip -o -d /home/aistudio/data/ /home/aistudio/data/data1919/Road02.zip\n",
    "# !unzip -o -d /home/aistudio/data/ /home/aistudio/data/data1919/Road03.zip\n",
    "# !unzip -o -d /home/aistudio/data/ /home/aistudio/data/data1919/Road04.zip\n",
    "# !unzip -o -d /home/aistudio/data/ /home/aistudio/data/data1919/Labels_Fixed.zip\n",
    "!unzip -o -d /home/aistudio/data/ /home/aistudio/data/data2492/TestSet.zip\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/aistudio/data/Test_data2/Label_road04/Label/Record001/Camera': No such file or directory\r\n",
      "ls: cannot access '5/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/aistudio/data/Test_data2/\n",
    "# import zipfile\n",
    "# z = zipfile.ZipFile('/home/aistudio/data/data1919/Labels_Fixed.zip', 'r')\n",
    "# z.extractall(path=\"/home/aistudio/data/Test_data2/\")\n",
    "# z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number 999\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import six\n",
    "import random\n",
    "from PIL import Image\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "#------------------------------Dataset---------------------------------------------------\n",
    "# BaiduCarDataset\n",
    "# BaiduCarTestDataset\n",
    "#------------------------------\n",
    "Label = namedtuple( 'Label' , ['name' ,'id','trainId','category','categoryId','hasInstances','ignoreInEval','color'] )\n",
    "labels = [\n",
    "# name id trainId category catId hasInstances ignoreInEval color\n",
    "Label( 'void' , 0 , 0, 'void' , 0 , False , False , ( 0, 0, 0) ),\n",
    "Label( 's_w_d' , 200 , 1 , 'dividing' , 1 , False , False , ( 70, 130, 180) ),\n",
    "Label( 's_y_d' , 204 , 1 , 'dividing' , 1 , False , False , (220, 20, 60) ),\n",
    "Label( 'ds_w_dn' , 213 , 1 , 'dividing' , 1 , False , True , (128, 0, 128) ),\n",
    "Label( 'ds_y_dn' , 209 , 1 , 'dividing' , 1 , False , False , (255, 0, 0) ),\n",
    "Label( 'sb_w_do' , 206 , 1 , 'dividing' , 1 , False , True , ( 0, 0, 60) ),\n",
    "Label( 'sb_y_do' , 207 , 1 , 'dividing' , 1 , False , True , ( 0, 60, 100) ),\n",
    "Label( 'b_w_g' , 201 , 2 , 'guiding' , 2 , False , False , ( 0, 0, 142) ),\n",
    "Label( 'b_y_g' , 203 , 2 , 'guiding' , 2 , False , False , (119, 11, 32) ),\n",
    "Label( 'db_w_g' , 211 , 2 , 'guiding' , 2 , False , True , (244, 35, 232) ),\n",
    "Label( 'db_y_g' , 208 , 2 , 'guiding' , 2 , False , True , ( 0, 0, 160) ),\n",
    "Label( 'db_w_s' , 216 , 3 , 'stopping' , 3 , False , True , (153, 153, 153) ),\n",
    "Label( 's_w_s' , 217 , 3 , 'stopping' , 3 , False , False , (220, 220, 0) ),\n",
    "Label( 'ds_w_s' , 215 , 3 , 'stopping' , 3 , False , True , (250, 170, 30) ),\n",
    "Label( 's_w_c' , 218 , 4 , 'chevron' , 4 , False , True , (102, 102, 156) ),\n",
    "Label( 's_y_c' , 219 , 4 , 'chevron' , 4 , False , True , (128, 0, 0) ),\n",
    "Label( 's_w_p' , 210 , 5 , 'parking' , 5 , False , False , (128, 64, 128) ),\n",
    "Label( 's_n_p' , 232 , 5 , 'parking' , 5 , False , True , (238, 232, 170) ),\n",
    "Label( 'c_wy_z' , 214 , 6 , 'zebra' , 6 , False , False , (190, 153, 153) ),\n",
    "Label( 'a_w_u' , 202 , 7 , 'thru/turn' , 7 , False , True , ( 0, 0, 230) ),\n",
    "Label( 'a_w_t' , 220 , 7 , 'thru/turn' , 7 , False , False , (128, 128, 0) ),\n",
    "Label( 'a_w_tl' , 221 , 7 , 'thru/turn' , 7 , False , False , (128, 78, 160) ),\n",
    "Label( 'a_w_tr' , 222 , 7 , 'thru/turn' , 7 , False , False , (150, 100, 100) ),\n",
    "Label( 'a_w_tlr' , 231 , 7 , 'thru/turn' , 7 , False , True , (255, 165, 0) ),\n",
    "Label( 'a_w_l' , 224 , 7 , 'thru/turn' , 7 , False , False , (180, 165, 180) ),\n",
    "Label( 'a_w_r' , 225 , 7 , 'thru/turn' , 7 , False , False , (107, 142, 35) ),\n",
    "Label( 'a_w_lr' , 226 , 7 , 'thru/turn' , 7 , False , False , (201, 255, 229) ),\n",
    "Label( 'a_n_lu' , 230 , 7 , 'thru/turn' , 7 , False , True , (0, 191, 255) ),\n",
    "Label( 'a_w_tu' , 228 , 7 , 'thru/turn' , 7 , False , True , ( 51, 255, 51) ),\n",
    "Label( 'a_w_m' , 229 , 7 , 'thru/turn' , 7 , False , True , (250, 128, 114) ),\n",
    "Label( 'a_y_t' , 233 , 7 , 'thru/turn' , 7 , False , True , (127, 255, 0) ),\n",
    "Label( 'b_n_sr' , 205 , 8 , 'reduction' , 8 , False , False , (255, 128, 0) ),\n",
    "Label( 'd_wy_za' , 212 , 8 , 'attention' , 8 , False , True , ( 0, 255, 255) ),\n",
    "Label( 'r_wy_np' , 227 , 8 , 'no parking' , 8 , False , False , (178, 132, 190) ),\n",
    "Label( 'vom_wy_n' , 223 , 8 , 'others' , 8 , False , True , (128, 128, 64) ),\n",
    "Label( 'om_n_n' , 250 , 8 , 'others' , 8 , False , False , (102, 0, 204) ),\n",
    "Label( 'noise' , 249 , 0 , 'ignored' , 0 , False , True , ( 0, 153, 153) ),\n",
    "Label( 'ignored' , 255 , 0 , 'ignored' , 0 , False , True , (255, 255, 255) ),\n",
    "]\n",
    "\n",
    "\n",
    "default_config = {\n",
    "    \"shuffle\": True,\n",
    "    \"crop_size\": (769,769)\n",
    "}\n",
    "\n",
    "infer_config = {\n",
    "    \"shuffle\": False,\n",
    "    \"crop_size\": (-1,-1),\n",
    "}\n",
    "\n",
    "def slice_with_pad(a, s, value=0):\n",
    "    pads = []\n",
    "    slices = []\n",
    "    for i in range(len(a.shape)):\n",
    "        if i >= len(s):\n",
    "            pads.append([0, 0])\n",
    "            slices.append([0, a.shape[i]])\n",
    "        else:\n",
    "            l, r = s[i]\n",
    "            if l < 0:\n",
    "                pl = -l\n",
    "                l = 0\n",
    "            else:\n",
    "                pl = 0\n",
    "            if r > a.shape[i]:\n",
    "                pr = r - a.shape[i]\n",
    "                r = a.shape[i]\n",
    "            else:\n",
    "                pr = 0\n",
    "            pads.append([pl, pr])\n",
    "            slices.append([l, r])\n",
    "    slices = list(map(lambda x: slice(x[0], x[1], 1), slices))\n",
    "    a = a[slices]\n",
    "    a = np.pad(a, pad_width=pads, mode='constant', constant_values=value)\n",
    "    return a\n",
    "\n",
    "def image2label(label,cm2lbl):\n",
    "    data = np.array(label, dtype='int32')\n",
    "    idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "    return np.array(cm2lbl[idx], dtype='int64')  # 根据索引得到 label 矩阵\n",
    "\n",
    "class BaiduCarDataset:\n",
    "    def __init__(self, dataset_dir, subset='train', config=default_config, crop=False, flip_rate=0.):\n",
    "        label_dirname = os.path.join(dataset_dir, 'Label_road02/Label/')\n",
    "        label_files=list()\n",
    "        for dire in os.listdir(label_dirname):\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire,'Camera 5')):\n",
    "                    label_files.append(os.path.join(label_dirname, dire, 'Camera 5/', dir))\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire, 'Camera 6')):\n",
    "                label_files.append(os.path.join(label_dirname, dire, 'Camera 6/', dir))\n",
    "        label_dirname = os.path.join(dataset_dir, 'Label_road03/Label/')\n",
    "        for dire in os.listdir(label_dirname):\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire, 'Camera 5')):\n",
    "                label_files.append(os.path.join(label_dirname, dire, 'Camera 5/', dir))\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire, 'Camera 6')):\n",
    "                label_files.append(os.path.join(label_dirname, dire, 'Camera 6/', dir))\n",
    "        label_dirname = os.path.join(dataset_dir, 'Label_road04/Label/')\n",
    "        for dire in os.listdir(label_dirname):\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire, 'Camera 5')):\n",
    "                label_files.append(os.path.join(label_dirname, dire, 'Camera 5/', dir))\n",
    "            for dir in os.listdir(os.path.join(label_dirname, dire, 'Camera 6')):\n",
    "                label_files.append(os.path.join(label_dirname, dire, 'Camera 6/', dir))\n",
    "        self.label2grey = np.zeros(9, dtype='uint8')\n",
    "        for i in range(9):\n",
    "            for obj in labels:\n",
    "                if obj.trainId == i:\n",
    "                    self.label2grey[i] = obj.id\n",
    "        self.label_files = label_files\n",
    "        self.label_dirname = label_dirname\n",
    "        self.index = 0\n",
    "        self.subset = subset\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.config = config\n",
    "        self.crop=crop\n",
    "        self.flip_rate=flip_rate\n",
    "        self.cm2lbl = np.zeros(256 ** 3)  # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "        for obj in labels:\n",
    "            if obj.ignoreInEval:\n",
    "                color = obj.color\n",
    "                cm = color\n",
    "                self.cm2lbl[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = 9  # 建立索引\n",
    "                continue\n",
    "            idx = obj.trainId\n",
    "            color = obj.color\n",
    "            cm = color\n",
    "            self.cm2lbl[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = idx  # 建立索引\n",
    "        if subset == 'train':\n",
    "            self.crop = True\n",
    "            self.flip_rate = 0.5\n",
    "        self.new_h, self.new_w = self.config[\"crop_size\"]\n",
    "        self.reset()\n",
    "        print(\"total number\", len(label_files))\n",
    "\n",
    "    def reset(self, shuffle=False):\n",
    "        self.index = 0\n",
    "        if self.config[\"shuffle\"]:\n",
    "            np.random.shuffle(self.label_files)  #打乱顺序\n",
    "\n",
    "    def next_img(self):\n",
    "        self.index += 1\n",
    "        if self.index >= len(self.label_files):\n",
    "            self.reset()\n",
    "\n",
    "    def get_img(self):\n",
    "        while True:\n",
    "            ln = self.label_files[self.index]\n",
    "            img_name=ln\n",
    "            if 'Label_road02' in ln:\n",
    "                img_name = img_name.replace('Label_road02/Label/', 'ColorImage_road02/ColorImage/')\n",
    "                img_name = img_name.replace('_bin.png', '.jpg')\n",
    "            elif 'Label_road03' in ln:\n",
    "                img_name = img_name.replace('Label_road03/Label/', 'ColorImage_road03/ColorImage/')\n",
    "                img_name = img_name.replace('_bin.png', '.jpg')\n",
    "            elif 'Label_road04' in ln:\n",
    "                img_name = img_name.replace('Label_road04/Label/', 'ColorImage_road04/ColorImage/')\n",
    "                img_name = img_name.replace('_bin.png', '.jpg')\n",
    "            label = Image.open(ln).convert('RGB')\n",
    "            label = np.asarray(label, dtype='int32')\n",
    "            label=image2label(label, self.cm2lbl)\n",
    "            # img = cv2.imread(img_name)\n",
    "            img = Image.open(img_name).convert('RGB')\n",
    "            img = np.asarray(img, dtype='int64')\n",
    "            if img is None:\n",
    "                print(\"load img failed:\", img_name)\n",
    "                self.next_img()\n",
    "            else:\n",
    "                break\n",
    "        if self.new_h == -1:\n",
    "            return img, label, ln\n",
    "        if self.crop:\n",
    "            h, w, _ = img.shape\n",
    "            top   = random.randint(0, h - self.new_h)\n",
    "            left  = random.randint(0, w - self.new_w)\n",
    "            img   = img[top:top + self.new_h, left:left + self.new_w]\n",
    "            label = label[top:top + self.new_h, left:left + self.new_w]\n",
    "\n",
    "        if random.random() < self.flip_rate:\n",
    "            img   = np.fliplr(img)\n",
    "            label = np.fliplr(label)\n",
    "\n",
    "        return img, label, ln\n",
    "\n",
    "    def get_batch(self, batch_size=1):\n",
    "        imgs = []\n",
    "        labels = []\n",
    "        names = []\n",
    "        while len(imgs) < batch_size:\n",
    "            img, label, ln = self.get_img()\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "            names.append(ln)\n",
    "            self.next_img()\n",
    "        return np.array(imgs), np.array(labels), names\n",
    "\n",
    "    def get_batch_generator(self, batch_size, total_step):\n",
    "        def do_get_batch():\n",
    "            for i in range(total_step):\n",
    "                imgs, labels, names = self.get_batch(batch_size)\n",
    "                labels = labels.astype(np.int32)\n",
    "                imgs = imgs[:, :, :, ::-1].transpose(\n",
    "                    0, 3, 1, 2).astype(np.float32) / (255.0 / 2) - 1\n",
    "                yield i, imgs, labels, names\n",
    "\n",
    "        batches = do_get_batch()\n",
    "        try:\n",
    "            from prefetch_generator import BackgroundGenerator\n",
    "            batches = BackgroundGenerator(batches, 100)\n",
    "        except:\n",
    "            print(\n",
    "                \"You can install 'prefetch_generator' for acceleration of data reading.\"\n",
    "            )\n",
    "        return batches\n",
    "\n",
    "\n",
    "class BaiduCarTestDataset:\n",
    "    def __init__(self, dataset_dir, subset='Test', config=infer_config, crop=False, flip_rate=0.):\n",
    "        img_dirname = os.path.join(dataset_dir, 'ColorImage/')\n",
    "        img_files=list()\n",
    "        for dir in os.listdir(img_dirname):\n",
    "            img_files.append(os.path.join(img_dirname, dir))\n",
    "\n",
    "        self.label2grey = np.zeros(9, dtype='uint8')\n",
    "        for i in range(9):\n",
    "            for obj in labels:\n",
    "                if obj.trainId == i:\n",
    "                    self.label2grey[i] = obj.id\n",
    "        self.img_files = img_files\n",
    "        self.img_dirname = img_dirname\n",
    "        self.index = 0\n",
    "        self.subset = subset\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.config = config\n",
    "        self.crop=crop\n",
    "        self.flip_rate=flip_rate\n",
    "        self.cm2lbl = np.zeros(256 ** 3)  # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "        for obj in labels:\n",
    "            if obj.ignoreInEval:\n",
    "                continue\n",
    "            idx = obj.trainId\n",
    "            color = obj.color\n",
    "            cm = color\n",
    "            self.cm2lbl[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = idx  # 建立索引\n",
    "        self.new_h, self.new_w = self.config[\"crop_size\"]\n",
    "        self.reset()\n",
    "        print(\"total number\", len(img_files))\n",
    "\n",
    "    def reset(self, shuffle=False):\n",
    "        self.index = 0\n",
    "        if self.config[\"shuffle\"]:\n",
    "            np.random.shuffle(self.img_files)  #打乱顺序\n",
    "\n",
    "    def next_img(self):\n",
    "        self.index += 1\n",
    "        if self.index >= len(self.img_files):\n",
    "            self.reset()\n",
    "\n",
    "    def get_img(self):\n",
    "        while True:\n",
    "            ln = self.img_files[self.index]\n",
    "            img_name=ln\n",
    "            img = Image.open(img_name).convert('RGB')\n",
    "            img = np.asarray(img, dtype='int64')\n",
    "            if img is None:\n",
    "                print(\"load img failed:\", img_name)\n",
    "                self.next_img()\n",
    "            else:\n",
    "                break\n",
    "        if self.new_h == -1:\n",
    "            return img, ln\n",
    "        if self.crop:\n",
    "            h, w, _ = img.shape\n",
    "            top   = random.randint(0, h - self.new_h)\n",
    "            left  = random.randint(0, w - self.new_w)\n",
    "            img   = img[top:top + self.new_h, left:left + self.new_w]\n",
    "\n",
    "        if random.random() < self.flip_rate:\n",
    "            img   = np.fliplr(img)\n",
    "\n",
    "        return img, ln\n",
    "\n",
    "    def get_batch(self, batch_size=1):\n",
    "        imgs = []\n",
    "        names = []\n",
    "        while len(imgs) < batch_size:\n",
    "            img, ln = self.get_img()\n",
    "            imgs.append(img)\n",
    "            names.append(ln)\n",
    "            self.next_img()\n",
    "        return np.array(imgs), names\n",
    "\n",
    "    def get_batch_generator(self, batch_size, total_step):\n",
    "        def do_get_batch():\n",
    "            for i in range(total_step):\n",
    "                imgs, names = self.get_batch(batch_size)\n",
    "                imgs = imgs[:, :, :, ::-1].transpose(\n",
    "                    0, 3, 1, 2).astype(np.float32) / (255.0 / 2) - 1\n",
    "                yield i, imgs, names\n",
    "\n",
    "        batches = do_get_batch()\n",
    "        try:\n",
    "            from prefetch_generator import BackgroundGenerator\n",
    "            batches = BackgroundGenerator(batches, 100)\n",
    "        except:\n",
    "            print(\n",
    "                \"You can install 'prefetch_generator' for acceleration of data reading.\"\n",
    "            )\n",
    "        return batches\n",
    "\n",
    "\n",
    "#-----------------------------------model--------------------------------------------\n",
    "\n",
    "#----------------------------------------\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import contextlib\n",
    "\n",
    "name_scope = \"\"\n",
    "op_results = {}\n",
    "class model:\n",
    "    def __init__(self, bn_momentum = 0.99, dropout_keep_prop = 0.9, is_train = True, label_number = 9):\n",
    "\n",
    "        # name_scope = \"\"\n",
    "        # op_results = {}\n",
    "\n",
    "        self.decode_channel = 48\n",
    "        self.encode_channel = 256\n",
    "        self.label_number = label_number\n",
    "\n",
    "        self.bn_momentum = bn_momentum\n",
    "        self.dropout_keep_prop = dropout_keep_prop\n",
    "        self.is_train = is_train\n",
    "\n",
    "\n",
    "        self.default_epsilon = 1e-3\n",
    "        self.default_norm_type = 'bn'\n",
    "        self.default_group_number = 32\n",
    "        self.depthwise_use_cudnn = False\n",
    "\n",
    "        self.bn_regularizer = fluid.regularizer.L2DecayRegularizer(regularization_coeff=0.0)\n",
    "        self.depthwise_regularizer = fluid.regularizer.L2DecayRegularizer(\n",
    "                regularization_coeff=0.0)\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def scope(self, name):\n",
    "        global name_scope\n",
    "        bk = name_scope\n",
    "        name_scope = name_scope + name + '/'\n",
    "        yield\n",
    "        name_scope = bk\n",
    "\n",
    "    def check(self, data, number):\n",
    "        if type(data) == int:\n",
    "            return [data] * number\n",
    "        assert len(data) == number\n",
    "        return data\n",
    "\n",
    "    def clean(self):\n",
    "        global op_results\n",
    "        op_results = {}\n",
    "\n",
    "    def append_op_result(self, result, name):\n",
    "        global op_results\n",
    "        op_index = len(op_results)\n",
    "        name = name_scope + name + str(op_index)\n",
    "        op_results[name] = result\n",
    "        return result\n",
    "\n",
    "    def conv(self, *args, **kargs):\n",
    "        if \"xception\" in name_scope:\n",
    "            init_std = 0.09\n",
    "        elif \"logit\" in name_scope:\n",
    "            init_std = 0.01\n",
    "        elif name_scope.endswith('depthwise/'):\n",
    "            init_std = 0.33\n",
    "        else:\n",
    "            init_std = 0.06\n",
    "        if name_scope.endswith('depthwise/'):\n",
    "            regularizer = self.depthwise_regularizer\n",
    "        else:\n",
    "            regularizer = None\n",
    "\n",
    "        kargs['param_attr'] = fluid.ParamAttr(\n",
    "            name=name_scope + 'weights',\n",
    "            regularizer=regularizer,\n",
    "            initializer=fluid.initializer.TruncatedNormal(\n",
    "                loc=0.0, scale=init_std))\n",
    "        if 'bias_attr' in kargs and kargs['bias_attr']:\n",
    "            kargs['bias_attr'] = fluid.ParamAttr(\n",
    "                name=name_scope + 'biases',\n",
    "                regularizer=regularizer,\n",
    "                initializer=fluid.initializer.ConstantInitializer(value=0.0))\n",
    "        else:\n",
    "            kargs['bias_attr'] = False\n",
    "        kargs['name'] = name_scope + 'conv'\n",
    "        return self.append_op_result(fluid.layers.conv2d(*args, **kargs), 'conv')\n",
    "\n",
    "    def group_norm(self, input, G, eps=1e-5, param_attr=None, bias_attr=None):\n",
    "        N, C, H, W = input.shape\n",
    "        if C % G != 0:\n",
    "            # print \"group can not divide channle:\", C, G\n",
    "            for d in range(10):\n",
    "                for t in [d, -d]:\n",
    "                    if G + t <= 0: continue\n",
    "                    if C % (G + t) == 0:\n",
    "                        G = G + t\n",
    "                        break\n",
    "                if C % G == 0:\n",
    "                    # print \"use group size:\", G\n",
    "                    break\n",
    "        assert C % G == 0\n",
    "        x = fluid.layers.group_norm(\n",
    "            input,\n",
    "            groups=G,\n",
    "            param_attr=param_attr,\n",
    "            bias_attr=bias_attr,\n",
    "            name=name_scope + 'group_norm')\n",
    "        return x\n",
    "\n",
    "    def bn(self, *args, **kargs):\n",
    "        if self.default_norm_type == 'bn':\n",
    "            with self.scope('BatchNorm'):\n",
    "                return self.append_op_result(\n",
    "                    fluid.layers.batch_norm(\n",
    "                        *args,\n",
    "                        epsilon=default_epsilon,\n",
    "                        momentum=self.bn_momentum,\n",
    "                        param_attr=fluid.ParamAttr(\n",
    "                            name=name_scope + 'gamma', regularizer=self.bn_regularizer),\n",
    "                        bias_attr=fluid.ParamAttr(\n",
    "                            name=name_scope + 'beta', regularizer=self.bn_regularizer),\n",
    "                        moving_mean_name=name_scope + 'moving_mean',\n",
    "                        moving_variance_name=name_scope + 'moving_variance',\n",
    "                        **kargs),\n",
    "                    'bn')\n",
    "        elif self.default_norm_type == 'gn':\n",
    "            with self.scope('GroupNorm'):\n",
    "                return self.append_op_result(\n",
    "                    self.group_norm(\n",
    "                        args[0],\n",
    "                        self.default_group_number,\n",
    "                        eps=default_epsilon,\n",
    "                        param_attr=fluid.ParamAttr(\n",
    "                            name=name_scope + 'gamma', regularizer=self.bn_regularizer),\n",
    "                        bias_attr=fluid.ParamAttr(\n",
    "                            name=name_scope + 'beta', regularizer=self.bn_regularizer)),\n",
    "                    'gn')\n",
    "        else:\n",
    "            raise \"Unsupport norm type:\" + self.default_norm_type\n",
    "\n",
    "    def bn_relu(self, data):\n",
    "        return self.append_op_result(fluid.layers.relu(self.bn(data)), 'relu')\n",
    "\n",
    "    def relu(self, data):\n",
    "        return self.append_op_result(fluid.layers.relu(data), 'relu')\n",
    "\n",
    "    def seq_conv(self, input, channel, stride, filter, dilation=1, act=None):\n",
    "        with self.scope('depthwise'):\n",
    "            input = self.conv(\n",
    "                input,\n",
    "                input.shape[1],\n",
    "                filter,\n",
    "                stride,\n",
    "                groups=input.shape[1],\n",
    "                padding=(filter // 2) * dilation,\n",
    "                dilation=dilation,\n",
    "                use_cudnn=self.depthwise_use_cudnn)\n",
    "            input = self.bn(input)\n",
    "            if act: input = act(input)\n",
    "        with self.scope('pointwise'):\n",
    "            input = self.conv(input, channel, 1, 1, groups=1, padding=0)\n",
    "            input = self.bn(input)\n",
    "            if act: input = act(input)\n",
    "        return input\n",
    "\n",
    "    def xception_block(self, input,\n",
    "                       channels,\n",
    "                       strides=1,\n",
    "                       filters=3,\n",
    "                       dilation=1,\n",
    "                       skip_conv=True,\n",
    "                       has_skip=True,\n",
    "                       activation_fn_in_separable_conv=False):\n",
    "        repeat_number = 3\n",
    "        channels = self.check(channels, repeat_number)\n",
    "        filters = self.check(filters, repeat_number)\n",
    "        strides = self.check(strides, repeat_number)\n",
    "        data = input\n",
    "        results = []\n",
    "        for i in range(repeat_number):\n",
    "            with self.scope('separable_conv' + str(i + 1)):\n",
    "                if not activation_fn_in_separable_conv:\n",
    "                    data = self.relu(data)\n",
    "                    data = self.seq_conv(\n",
    "                        data,\n",
    "                        channels[i],\n",
    "                        strides[i],\n",
    "                        filters[i],\n",
    "                        dilation=dilation)\n",
    "                else:\n",
    "                    data = self.seq_conv(\n",
    "                        data,\n",
    "                        channels[i],\n",
    "                        strides[i],\n",
    "                        filters[i],\n",
    "                        dilation=dilation,\n",
    "                        act=self.relu)\n",
    "                results.append(data)\n",
    "        if not has_skip:\n",
    "            return self.append_op_result(data, 'xception_block'), results\n",
    "        if skip_conv:\n",
    "            with self.scope('shortcut'):\n",
    "                skip = self.bn(\n",
    "                    self.conv(\n",
    "                        input, channels[-1], 1, strides[-1], groups=1, padding=0))\n",
    "        else:\n",
    "            skip = input\n",
    "        return self.append_op_result(data + skip, 'xception_block'), results\n",
    "\n",
    "    def entry_flow(self, data):\n",
    "        with self.scope(\"entry_flow\"):\n",
    "            with self.scope(\"conv1\"):\n",
    "                data = self.conv(data, 32, 3, stride=2, padding=1)\n",
    "                data = self.bn_relu(data)\n",
    "            with self.scope(\"conv2\"):\n",
    "                data = self.conv(data, 64, 3, stride=1, padding=1)\n",
    "                data = self.bn_relu(data)\n",
    "            with self.scope(\"block1\"):\n",
    "                data, _ = self.xception_block(data, 128, [1, 1, 2])\n",
    "            with self.scope(\"block2\"):\n",
    "                data, results = self.xception_block(data, 256, [1, 1, 2])\n",
    "            with self.scope(\"block3\"):\n",
    "                data, _ = self.xception_block(data, 728, [1, 1, 2])\n",
    "            return data, results[1]\n",
    "\n",
    "    def middle_flow(self, data):\n",
    "        with self.scope(\"middle_flow\"):\n",
    "            for i in range(16):\n",
    "                with self.scope(\"block\" + str(i + 1)):\n",
    "                    data, _ = self.xception_block(data, 728, [1, 1, 1], skip_conv=False)\n",
    "        return data\n",
    "\n",
    "    def exit_flow(self, data):\n",
    "        with self.scope(\"exit_flow\"):\n",
    "            with self.scope('block1'):\n",
    "                data, _ = self.xception_block(data, [728, 1024, 1024], [1, 1, 1])\n",
    "            with self.scope('block2'):\n",
    "                data, _ = self.xception_block(\n",
    "                    data, [1536, 1536, 2048], [1, 1, 1],\n",
    "                    dilation=2,\n",
    "                    has_skip=False,\n",
    "                    activation_fn_in_separable_conv=True)\n",
    "            return data\n",
    "\n",
    "    def dropout(self, x, keep_rate):\n",
    "        if self.is_train:\n",
    "            return fluid.layers.dropout(x, 1 - keep_rate) / keep_rate\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def encoder(self, input):\n",
    "        with self.scope('encoder'):\n",
    "            channel = 256\n",
    "            with self.scope(\"image_pool\"):\n",
    "                image_avg = fluid.layers.reduce_mean(input, [2, 3], keep_dim=True)\n",
    "                self.append_op_result(image_avg, 'reduce_mean')\n",
    "                image_avg = self.bn_relu(\n",
    "                    self.conv(\n",
    "                        image_avg, channel, 1, 1, groups=1, padding=0))\n",
    "                image_avg = fluid.layers.resize_bilinear(image_avg, input.shape[2:])\n",
    "\n",
    "            with self.scope(\"aspp0\"):\n",
    "                aspp0 = self.bn_relu(self.conv(input, channel, 1, 1, groups=1, padding=0))\n",
    "            with self.scope(\"aspp1\"):\n",
    "                aspp1 = self.seq_conv(input, channel, 1, 3, dilation=6, act=self.relu)\n",
    "            with self.scope(\"aspp2\"):\n",
    "                aspp2 = self.seq_conv(input, channel, 1, 3, dilation=12, act=self.relu)\n",
    "            with self.scope(\"aspp3\"):\n",
    "                aspp3 = self.seq_conv(input, channel, 1, 3, dilation=18, act=self.relu)\n",
    "            with self.scope(\"concat\"):\n",
    "                data = self.append_op_result(\n",
    "                    fluid.layers.concat(\n",
    "                        [image_avg, aspp0, aspp1, aspp2, aspp3], axis=1),\n",
    "                    'concat')\n",
    "                data = self.bn_relu(self.conv(data, channel, 1, 1, groups=1, padding=0))\n",
    "                data = self.dropout(data, self.dropout_keep_prop)\n",
    "            return data\n",
    "\n",
    "    def decoder(self, encode_data, decode_shortcut):\n",
    "        with self.scope('decoder'):\n",
    "            with self.scope('concat'):\n",
    "                decode_shortcut = self.bn_relu(\n",
    "                    self.conv(\n",
    "                        decode_shortcut, self.decode_channel, 1, 1, groups=1, padding=0))\n",
    "                encode_data = fluid.layers.resize_bilinear(\n",
    "                    encode_data, decode_shortcut.shape[2:])\n",
    "                encode_data = fluid.layers.concat(\n",
    "                    [encode_data, decode_shortcut], axis=1)\n",
    "                self.append_op_result(encode_data, 'concat')\n",
    "            with self.scope(\"separable_conv1\"):\n",
    "                encode_data = self.seq_conv(\n",
    "                    encode_data, self.encode_channel, 1, 3, dilation=1, act=self.relu)\n",
    "            with self.scope(\"separable_conv2\"):\n",
    "                encode_data = self.seq_conv(\n",
    "                    encode_data, self.encode_channel, 1, 3, dilation=1, act=self.relu)\n",
    "            return encode_data\n",
    "\n",
    "    def deeplabv3p(self, img):\n",
    "        global default_epsilon\n",
    "        self.append_op_result(img, 'img')\n",
    "        with self.scope('xception_65'):\n",
    "            default_epsilon = 1e-3\n",
    "            # Entry flow\n",
    "            data, decode_shortcut = self.entry_flow(img)\n",
    "            # Middle flow\n",
    "            data = self.middle_flow(data)\n",
    "            # Exit flow\n",
    "            data = self.exit_flow(data)\n",
    "        default_epsilon = 1e-5\n",
    "        encode_data = self.encoder(data)\n",
    "        encode_data = self.decoder(encode_data, decode_shortcut)\n",
    "        with self.scope('logit'):\n",
    "            logit = self.conv(\n",
    "                encode_data, self.label_number, 1, stride=1, padding=0, bias_attr=True)\n",
    "            logit = fluid.layers.resize_bilinear(logit, img.shape[2:])\n",
    "        return logit\n",
    "\n",
    "\n",
    "#--------------------------------------------train------------------------------------\n",
    "import os\n",
    "os.environ['FLAGS_fraction_of_gpu_memory_to_use'] = '0.9'\n",
    "import time\n",
    "\n",
    "class train:\n",
    "    def __init__(self, init_weights_path = None, save_weights_path = None,\n",
    "                 dataset_path=None, train_crop_size=769, total_step=1000):\n",
    "        self.batch_size = 1\n",
    "        self.base_lr = 0.0001\n",
    "        self.total_step = total_step\n",
    "        self.init_weights_path = init_weights_path\n",
    "        self.save_weights_path = save_weights_path\n",
    "        self.dataset_path = dataset_path\n",
    "        self.parallel = False\n",
    "        self.use_gpu = True\n",
    "        self.num_classes = 9\n",
    "        self.no_grad_set = set()\n",
    "        self.crop_size = train_crop_size\n",
    "        self.weight_decay = 0.00004\n",
    "        self.use_gpu=False\n",
    "        self.parallel=False\n",
    "    def load_model(self, tp, exe):\n",
    "        myvars = [\n",
    "            x for x in tp.list_vars()\n",
    "            if isinstance(x, fluid.framework.Parameter) and x.name.find('logit') ==\n",
    "            -1\n",
    "        ]\n",
    "        if self.init_weights_path.endswith('/'):\n",
    "            if self.num_classes == 9:\n",
    "                fluid.io.load_params(\n",
    "                    exe, dirname=self.init_weights_path, main_program=tp)\n",
    "            else:\n",
    "                fluid.io.load_vars(exe, dirname=self.init_weights_path, vars=myvars)\n",
    "        else:\n",
    "            if self.num_classes == 9:\n",
    "                fluid.io.load_params(\n",
    "                    exe,\n",
    "                    dirname=\"\",\n",
    "                    filename=self.init_weights_path,\n",
    "                    main_program=tp)\n",
    "            else:\n",
    "                fluid.io.load_vars(\n",
    "                    exe, dirname=\"\", filename=self.init_weights_path, vars=myvars)\n",
    "\n",
    "    def save_model(self, tp, exe):\n",
    "        if self.save_weights_path.endswith('/'):\n",
    "            fluid.io.save_params(\n",
    "                exe, dirname=self.save_weights_path, main_program=tp)\n",
    "        else:\n",
    "            fluid.io.save_params(\n",
    "                exe, dirname=\"\", filename=self.save_weights_path, main_program=tp)\n",
    "\n",
    "    def loss(self, logit, label):\n",
    "        label_nignore = (label < self.num_classes).astype('float32')\n",
    "        label_zero = (label==0).astype('float32')\n",
    "        label_nignore = label_nignore - 0.98*label_zero\n",
    "        label = fluid.layers.elementwise_min(\n",
    "            label,\n",
    "            fluid.layers.assign(np.array(\n",
    "                [self.num_classes - 1], dtype=np.int32)))\n",
    "        logit = fluid.layers.transpose(logit, [0, 2, 3, 1])\n",
    "        logit = fluid.layers.reshape(logit, [-1, self.num_classes])\n",
    "        label = fluid.layers.reshape(label, [-1, 1])\n",
    "        label = fluid.layers.cast(label, 'int64')\n",
    "        label_nignore = fluid.layers.reshape(label_nignore, [-1, 1])\n",
    "        # label_zero = fluid.layers.reshape(label_zero, [-1, 1])\n",
    "        loss = fluid.layers.softmax_with_cross_entropy(logit, label, ignore_index=9)\n",
    "        loss = loss * label_nignore\n",
    "        self.no_grad_set.add(label_nignore.name)\n",
    "        self.no_grad_set.add(label.name)\n",
    "        return loss, label_nignore\n",
    "\n",
    "    def training(self):\n",
    "\n",
    "        model_t=model(bn_momentum=0.9997, dropout_keep_prop=0.9, label_number = self.num_classes )\n",
    "        model_t.clean()\n",
    "        deeplabv3p = model_t.deeplabv3p\n",
    "\n",
    "        sp = fluid.Program()\n",
    "        tp = fluid.Program()\n",
    "\n",
    "\n",
    "        image_shape = [self.crop_size, self.crop_size]\n",
    "\n",
    "        with fluid.program_guard(tp, sp):\n",
    "            img = fluid.layers.data(\n",
    "                name='img', shape=[3] + image_shape, dtype='float32')\n",
    "            label = fluid.layers.data(name='label', shape=image_shape, dtype='int32')\n",
    "            logit = deeplabv3p(img)\n",
    "            pred = fluid.layers.argmax(logit, axis=1).astype('int32')\n",
    "            loss, mask = self.loss(logit, label)\n",
    "            # lr = fluid.layers.polynomial_decay(\n",
    "            #     base_lr, total_step, end_learning_rate=0, power=0.9)\n",
    "            lr = self.base_lr\n",
    "            area = fluid.layers.elementwise_max(\n",
    "                fluid.layers.reduce_mean(mask),\n",
    "                fluid.layers.assign(np.array(\n",
    "                    [0.1], dtype=np.float32)))\n",
    "            loss_mean = fluid.layers.reduce_mean(loss) / area\n",
    "\n",
    "            opt = fluid.optimizer.Adam(\n",
    "                lr,\n",
    "                # momentum=0.9,\n",
    "                regularization=fluid.regularizer.L2DecayRegularizer(\n",
    "                    regularization_coeff=self.weight_decay), )\n",
    "            retv = opt.minimize(loss_mean, startup_program=sp, no_grad_set=self.no_grad_set)\n",
    "\n",
    "        fluid.memory_optimize(\n",
    "            tp, print_log=False, skip_opt_set=set([pred.name, loss_mean.name]), level=1)\n",
    "\n",
    "        place = fluid.CPUPlace()\n",
    "        if self.use_gpu:\n",
    "            place = fluid.CUDAPlace(0)\n",
    "        exe = fluid.Executor(place)\n",
    "        exe.run(sp)\n",
    "\n",
    "        if self.init_weights_path:\n",
    "            print(\"load from:\", self.init_weights_path)\n",
    "            self.load_model(tp, exe)\n",
    "\n",
    "        default_config['crop_size'] = (self.crop_size,self.crop_size)\n",
    "        default_config['shuffle'] = True\n",
    "        dataset = BaiduCarDataset(self.dataset_path, 'train', default_config)\n",
    "\n",
    "        if self.parallel:\n",
    "            exe_p = fluid.ParallelExecutor(\n",
    "                use_cuda=True, loss_name=loss_mean.name, main_program=tp)\n",
    "        #\n",
    "        batches = dataset.get_batch_generator(self.batch_size, self.total_step)\n",
    "\n",
    "        total_time = 0.0\n",
    "        epoch_idx = 0\n",
    "        train_loss = 0\n",
    "\n",
    "        for i, imgs, labels, names in batches:\n",
    "            epoch_idx += 1\n",
    "            begin_time = time.time()\n",
    "            prev_start_time = time.time()\n",
    "            if self.parallel:\n",
    "                retv = exe_p.run(fetch_list=[pred.name, loss_mean.name],\n",
    "                                 feed={'img': imgs,\n",
    "                                       'label': labels})\n",
    "            else:\n",
    "                retv = exe.run(tp,\n",
    "                               feed={'img': imgs,\n",
    "                                     'label': labels},\n",
    "                               fetch_list=[pred, loss_mean])\n",
    "            end_time = time.time()\n",
    "            total_time += end_time - begin_time\n",
    "            if i % 100 == 0:\n",
    "                print(\"Model is saved to\", self.save_weights_path)\n",
    "                self.save_model(tp, exe)\n",
    "            print(\"step {:d}, loss: {:.6f}, step_time_cost: {:.3f}\".format(\n",
    "                i, np.mean(retv[1]), end_time - prev_start_time))\n",
    "\n",
    "            # only for ce\n",
    "            train_loss = np.mean(retv[1])\n",
    "\n",
    "        print(\"Training done. Model is saved to\", self.save_weights_path)\n",
    "        self.save_model(tp, exe)\n",
    "\n",
    "#--------------------------------------------infer------------------------------------\n",
    "\n",
    "class infer:\n",
    "    def __init__(self, init_weights_path = None, dataset_path=None, total_step=1000):\n",
    "        self.batch_size = 1\n",
    "        self.total_step = total_step\n",
    "        self.init_weights_path = init_weights_path\n",
    "        self.dataset_path = dataset_path\n",
    "        self.parallel = False\n",
    "        self.use_gpu = True\n",
    "        self.num_classes = 9\n",
    "        self.no_grad_set = set()\n",
    "        self.crop_size = -1\n",
    "        self.use_gpu=False\n",
    "        self.parallel=False\n",
    "    def load_model(self, tp, exe):\n",
    "        myvars = [\n",
    "            x for x in tp.list_vars()\n",
    "            if isinstance(x, fluid.framework.Parameter) and x.name.find('logit') ==\n",
    "            -1\n",
    "        ]\n",
    "        if self.init_weights_path.endswith('/'):\n",
    "            if self.num_classes == 9:\n",
    "                fluid.io.load_params(\n",
    "                    exe, dirname=self.init_weights_path, main_program=tp)\n",
    "            else:\n",
    "                fluid.io.load_vars(exe, dirname=self.init_weights_path, vars=myvars)\n",
    "        else:\n",
    "            if self.num_classes == 9:\n",
    "                fluid.io.load_params(\n",
    "                    exe,\n",
    "                    dirname=\"\",\n",
    "                    filename=self.init_weights_path,\n",
    "                    main_program=tp)\n",
    "            else:\n",
    "                fluid.io.load_vars(\n",
    "                    exe, dirname=\"\", filename=self.init_weights_path, vars=myvars)\n",
    "\n",
    "    def mean_iou(self, pred, label):\n",
    "        label = fluid.layers.elementwise_min(\n",
    "            label, fluid.layers.assign(np.array(\n",
    "                [self.num_classes], dtype=np.int32)))\n",
    "        label_ignore = (label == self.num_classes).astype('int32')\n",
    "        label_nignore = (label != self.num_classes).astype('int32')\n",
    "\n",
    "        pred = pred * label_nignore + label_ignore * self.num_classes\n",
    "        pred = pred\n",
    "        miou, wrong, correct = fluid.layers.mean_iou(pred, label, self.num_classes + 1)\n",
    "        return miou, wrong, correct\n",
    "\n",
    "    def infering(self):\n",
    "\n",
    "        model_t=model(bn_momentum=0.9997, dropout_keep_prop=0.9, label_number = self.num_classes )\n",
    "        model_t.clean()\n",
    "        model_t.is_train = False\n",
    "        deeplabv3p = model_t.deeplabv3p\n",
    "\n",
    "        sp = fluid.Program()\n",
    "        tp = fluid.Program()\n",
    "\n",
    "        image_shape = [1711, 3385]\n",
    "        eval_shape = [1710, 3384]\n",
    "\n",
    "        with fluid.program_guard(tp, sp):\n",
    "            img = fluid.layers.data(name='img', shape=[3, 0, 0], dtype='float32')\n",
    "            img = fluid.layers.resize_bilinear(img, image_shape)\n",
    "            logit = deeplabv3p(img)\n",
    "            logit = fluid.layers.resize_bilinear(logit, eval_shape)\n",
    "            pred = fluid.layers.argmax(logit, axis=1).astype('int32')\n",
    "\n",
    "        tp = tp.clone(True)\n",
    "\n",
    "        fluid.memory_optimize(\n",
    "            tp,\n",
    "            print_log=False,\n",
    "            skip_opt_set=set([pred.name]),\n",
    "            level=1)\n",
    "\n",
    "        place = fluid.CPUPlace()\n",
    "        if self.use_gpu:\n",
    "            place = fluid.CUDAPlace(0)\n",
    "        exe = fluid.Executor(place)\n",
    "        exe.run(sp)\n",
    "\n",
    "        if self.init_weights_path:\n",
    "            print(\"load from:\", self.init_weights_path)\n",
    "            self.load_model(tp, exe)\n",
    "        #\n",
    "        dataset = BaiduCarTestDataset(self.dataset_path, 'Test')\n",
    "        label2grey = dataset.label2grey\n",
    "        total_step = self.total_step\n",
    "        batches = dataset.get_batch_generator(self.batch_size, total_step)\n",
    "        #\n",
    "        import matplotlib.pyplot as plt\n",
    "        %matplotlib inline\n",
    "        for i, imgs, names in batches:\n",
    "            result = exe.run(tp,\n",
    "                             feed={'img': imgs,\n",
    "                                   },\n",
    "                             fetch_list=[pred])\n",
    "            # print(result[0].shape)\n",
    "            pre = np.squeeze(result[0], 0).astype('uint8')\n",
    "            print(i)\n",
    "            plt.imshow(pre)\n",
    "            # plt.show()\n",
    "            # plt.imshow(label2grey[pre])\n",
    "            # plt.show()\n",
    "            # pre1=np.zeros(pre).astype('uint8')\n",
    "            # png=Image.fromarray(label2grey[pre])\n",
    "            # plt.imshow(png)\n",
    "            # plt.show()\n",
    "            # name=names[0].replace('/TestSet/ColorImage/', '/test/road_name/')\n",
    "            # name=name.replace('.jpg', '.png')\n",
    "            # png.save(name)\n",
    "\n",
    "\n",
    "#--------------------------------------------main------------------------------------\n",
    "\n",
    "def main():\n",
    "    train_crop_size = 769\n",
    "    total_step = 1\n",
    "    init_weights_path = None\n",
    "    save_weights_path = './checkpoint/point29/'\n",
    "    dataset_path = '/home/aistudio/data/'\n",
    "    # Train=train(init_weights_path,save_weights_path,dataset_path,train_crop_size=train_crop_size,total_step=total_step)\n",
    "    # Train.training()\n",
    "    Infer=infer(init_weights_path, dataset_path,total_step)\n",
    "    Infer.infering()\n",
    "    # dataset = BaiduCarDataset(dataset_path, 'train', default_config)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # !pip install prefetch_generator\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.2.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
